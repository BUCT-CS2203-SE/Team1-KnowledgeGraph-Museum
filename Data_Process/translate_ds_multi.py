import pandas as pd
import requests
import concurrent.futures
import os
import time

# DeepSeek Chat API é…ç½®
API_URL = "https://api.deepseek.com/chat/completions"
API_KEY = "sk-cc7dfaf168f14940921cdc3866ff51de"

import re

HEADERS = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {API_KEY}"
}


# åˆ¤æ–­æ˜¯å¦ä¸ºä¸­æ–‡
def is_chinese(text):
    text = str(text).strip()
    if not text:
        return False
    return all('\u4e00' <= ch <= '\u9fff' for ch in text)


# ä¸éœ€è¦ç¿»è¯‘çš„åˆ—
SKIP_COLS = ['ImgUrl', 'ImgPath', 'main_start', 'main_end', 'id', 'sub_start', 'sub_end']


# ç¿»è¯‘
def translate_deepseek(text):
    payload = {
        "model": "deepseek-chat",
        "messages": [
            {"role": "system",
             "content": "ä½ æ˜¯ä¸€ä¸ªä¸­è‹±æ–‡ç¿»è¯‘åŠ©æ‰‹ã€‚è¯·å°†è‹±æ–‡ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚å¦‚æœè¾“å…¥æœ¬èº«æ˜¯ä¸­æ–‡ï¼Œåˆ™åŸæ ·è¿”å›ã€‚åªè¿”å›ç¿»è¯‘åçš„æ–‡æœ¬ï¼Œä¸è¦ä»»ä½•è§£é‡Šã€‚"},
            {"role": "user", "content": text}
        ],
        "temperature": 0.2
    }
    try:
        response = requests.post(API_URL, headers=HEADERS, json=payload, timeout=30)
        response.raise_for_status()
        result = response.json()
        return result["choices"][0]["message"]["content"].strip()
    except Exception as e:
        print(f"ç¿»è¯‘å¤±è´¥ï¼š{e}")
        return text

def process_row(index, row, translated_df):
    new_row = row.copy()
    row_id = str(row['id'])
    for col in row.index:
        if col in SKIP_COLS:
            continue
        val = row[col]
        if pd.isna(val):  # è·³è¿‡NaN
            continue

        # è¿™é‡Œæ”¹ç”¨ row_id ä»£æ›¿ index
        if col in translated_df.columns and row_id in translated_df.index and not pd.isna(translated_df.at[row_id, col]):
            continue
        if is_chinese(val):
            continue

        translated = translate_deepseek(str(val))
        new_row[col] = translated
        time.sleep(1)  # æ§åˆ¶é€Ÿç‡
    return index, new_row

# def process_row(index, row, translated_df):
#     new_row = row.copy()
#     row_id = str(row['id'])
#     for col in row.index:
#         if col in SKIP_COLS:
#             continue
#         val = row[col]
#         if pd.isna(val):  # è·³è¿‡NaN
#             continue
#         # if pd.isna(val) or val.strip() == "":
#         #     continue
#         # è‹¥å·²ç¿»è¯‘ï¼Œåˆ™è·³è¿‡
#         if col in translated_df.columns and not pd.isna(translated_df.at[index, col]):
#             continue
#         # è‹¥ä¸ºä¸­æ–‡ï¼Œä¹Ÿè·³è¿‡
#         if all('\u4e00' <= ch <= '\u9fff' for ch in str(val).strip()):
#             continue
#         if pd.isna(val) or val == "":
#             continue
#             # å¦‚æœè¯¥åˆ—è¯¥idå·²ç¿»è¯‘è¿‡ï¼Œåˆ™è·³è¿‡
#         if col in translated_df.columns and row_id in translated_df.index and pd.notna(translated_df.at[row_id, col]):
#             continue
#             # å¦‚æœå·²ç»æ˜¯ä¸­æ–‡ï¼Œè·³è¿‡
#         if is_chinese(val):
#             continue
#
#         translated = translate_deepseek(str(val))
#         new_row[col] = translated
#         time.sleep(1)  # æ§åˆ¶é€Ÿç‡
#     return index, new_row


# ä¸»æµç¨‹
def translate_csv_append(input_csv, output_csv, max_workers=3):
    df = pd.read_csv(input_csv, dtype=str)

    # ç¡®ä¿æ•´æ•°åˆ—ä¸ºå­—ç¬¦ä¸²è¯»å–ï¼Œåé¢ç»Ÿä¸€è½¬æ¢
    int_cols = ['id', 'main_start', 'main_end', 'sub_start', 'sub_end']

    translated_df = pd.DataFrame(columns=df.columns).set_index('id')

    # å¦‚æœå·²å­˜åœ¨è¾“å‡ºæ–‡ä»¶ï¼Œè¯»å–å·²ç¿»è¯‘æ•°æ®ï¼Œè®¾ç½®idä¸ºç´¢å¼•
    if os.path.exists(output_csv):
        translated_df = pd.read_csv(output_csv, dtype=str).set_index('id')
        print(f"å·²ç¿»è¯‘ {len(translated_df)} è¡Œï¼Œå°†è·³è¿‡")

    # ç­›é€‰å‡ºæ²¡ç¿»è¯‘è¿‡çš„è¡Œ
    untranslated = df[~df['id'].isin(translated_df.index)]

    print(f"å¾…ç¿»è¯‘è¡Œæ•°ï¼š{len(untranslated)}")

    # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå…ˆå†™è¡¨å¤´
    if not os.path.exists(output_csv):
        df.iloc[0:0].to_csv(output_csv, index=False)

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = []
        for idx, row in untranslated.iterrows():
            futures.append(executor.submit(process_row, idx, row, translated_df))

        for future in concurrent.futures.as_completed(futures):
            index, translated_row = future.result()

            # è½¬æ•´æ•°åˆ—ï¼Œé¿å…æµ®ç‚¹æˆ–å­—ç¬¦ä¸²æ ¼å¼ä¸ä¸€è‡´
            for col in int_cols:
                if col in translated_row and pd.notna(translated_row[col]):
                    try:
                        translated_row[col] = str(int(float(translated_row[col])))
                    except Exception:
                        translated_row[col] = ''

            # è¿½åŠ å†™å…¥csv
            pd.DataFrame([translated_row]).to_csv(output_csv, mode='a', index=False, header=False)
            print(f"âœ… å·²è¿½åŠ ç¿»è¯‘è¡Œ id={translated_row['id']}")

    print(f"ğŸ‰ ç¿»è¯‘å®Œæˆï¼Œç»“æœä¿å­˜äºï¼š{output_csv}")


if __name__ == "__main__":
    translate_csv_append("datasets/Process_time.csv", "datasets/Process_ds_multi2.csv", max_workers=10)

# def translate_csv(input_csv, output_csv, max_workers=4):
#     df = pd.read_csv(input_csv)
#     if os.path.exists(output_csv):
#         translated_df = pd.read_csv(output_csv)
#         print("ğŸ“‚ å·²åŠ è½½å·²æœ‰ç¿»è¯‘ç»“æœï¼Œç»§ç»­ç¿»è¯‘æœªå®Œæˆéƒ¨åˆ†...")
#     else:
#         translated_df = df.copy()
#         translated_df[:] = None  # åˆå§‹åŒ–ä¸ºç©º
#
#     total = len(df)
#     print(f"ğŸ“‹ å¾…ç¿»è¯‘è¡Œæ•°ï¼š{total}")
#
#     with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
#         futures = []
#         for i, row in df.iterrows():
#             futures.append(executor.submit(process_row, i, row, translated_df))
#
#         for future in concurrent.futures.as_completed(futures):
#             idx, updated_row = future.result()
#             translated_df.loc[idx] = updated_row
#             translated_df.to_csv(output_csv, index=False)  # å®æ—¶ä¿å­˜
#             print(f"âœ… å·²ç¿»è¯‘ç¬¬ {idx + 1} è¡Œ")
#
#     print(f"ğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼Œç¿»è¯‘ç»“æœä¿å­˜åœ¨ï¼š{output_csv}")

# ç¤ºä¾‹è¿è¡Œ
# translate_csv_append("datasets/Process_time.csv", "datasets/Process_ds_multi2.csv", max_workers=10)
