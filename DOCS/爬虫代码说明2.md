
### 史密斯学会

`Spider/Smithsonian/`

---

### 旧金山亚洲艺术博物馆

`Spider/Asian_Art_Museum`
该脚本（asian.py）用于从旧金山亚洲艺术博物馆（Asian Art Museum） 网站动态爬取与中国相关的文物信息，并将抓取结果保存为 CSV 文件。文物信息包括：标题、产地、时间、历史时期、材质、尺寸、来源、馆藏编号、部门、类别、是否展出、展厅、附加说明和图像链接。

#### 功能简介：

1. **浏览器自动化爬取**：使用 Selenium 控制浏览器访问带JavaScript动态加载的文物页面。
2. **提取详情页信息**：逐条访问文物详情页，提取结构化信息。
3. **保存为 CSV 文件**：将抓取结果组织为结构化表格并存储为 UTF-8 编码的 CSV 文件。
4. **中断续爬支持**：可选择跳过前 n 个文物，从中断处继续爬取。
------

### 主要模块与函数说明

#### 1. **全局配置参数**

```python
# 网站相关配置
root_url = "https://searchcollection.asianart.org"
base_url = "https://searchcollection.asianart.org/search/china/objects/list"

# 请求头配置（模拟浏览器访问，避免反爬）
headers = {
    "accept": "text/html, */*; q=0.01",
    "accept-language": "zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6",
    "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36 Edg/135.0.0.0",
    "x-requested-with": "XMLHttpRequest",
    "referer": "https://searchcollection.asianart.org/search/china/objects/list?page=2",
    "sec-fetch-mode": "cors",
    "sec-fetch-site": "same-origin",
    "priority": "u=1, i",
    "sec-ch-ua": "\"Microsoft Edge\";v=\"135\", \"Not-A.Brand\";v=\"8\", \"Chromium\";v=\"135\"",
    "sec-ch-ua-mobile": "?0",
    "sec-ch-ua-platform": "\"Windows\""
}

# Cookie 设置（维持会话，支持某些页面加载）
cookies = {
    "JSESSIONID": "6A686673CAD1486334503E227B47919F",
    "_gcl_au": "1.1.1950434450.1745369201",
    "_gid": "GA1.2.1526187988.1745369202",
    "_ga": "GA1.2.670806764.1745369201",
    "_ga_ET2P2QHM1T": "GS1.2.1745371131.2.1.1745375475.21.0.0",
    "_fbp": "fb.1.1745371131565.632400288850517901",
    "_hjSessionUser_1929636": "...",
    # 省略其他长 cookie 项，仅示意
}

# 图片保存路径前缀
image_folder = "images_china"
image_prefix = "asian_china"

# 输出 CSV 文件名
csv_output_file = "objects_china.csv"
```

- **root_url**：网站根地址，用于拼接图像链接和详情页链接。
- **base_url**：用于分页访问与“中国”相关文物列表的基础链接。
- **headers**：请求头，用于模拟真实浏览器访问，伪装为正常用户，减少被网站封锁或识别为爬虫的风险。
- **cookies**：浏览器 Cookie 信息，维持会话状态，确保页面可以正常加载内容。
- **image_folder**：本地保存图像的文件夹路径。例如，图片会被保存到 images_china/ 目录下。
- **image_prefix**：保存图像文件的统一前缀名，用于给图片命名，例如图片命名为 asian_china1.jpg、asian_china2.jpg 等。
- **csv_output_file**：最终爬取结果的输出 CSV 文件名，用于保存所有文物的结构化信息，如标题、描述、时间、图像链接等。

#### 2. **功能函数**
##### 2.1 `ownload_image(url, save_path)`

该函数用于下载文物图片并保存到本地指定路径。

- **参数**：
  - `url`: 图像的下载链接地址（字符串）。
  - `save_path`: 图像在本地保存的路径（字符串），如 'images_china/asian_china1.jpg'。
- **返回**：无返回值。函数执行过程中会在终端输出下载成功或失败的信息。

##### 2.2 `first_page(page)`

该函数访问亚洲艺术博物馆的搜索结果页，提取当前页所有文物的详情页链接。

- **参数**：
  - `page`: 当前页码，从1开始（整数）。
- **返回**：一个列表，包含当前页所有文物的完整详情页 URL（字符串列表）。

##### 2.3 `scrape_detail(u)`

该函数用于访问单个文物的详情页，提取全部字段信息并下载图像。

- **参数**：
  - `u`: 文物详情页的完整 URL（字符串）。
- **返回**：无显式返回值。函数会将提取的文物字段信息追加到全局列表 arts_info，同时下载该文物的图像并保存至本地。

##### 2.3 `save_object_data_to_csv(all_data, filename='objects_china.csv')`

该函数将所有抓取到的文物信息整理并保存为 CSV 文件。

- **参数**：
  - `all_data`: 包含所有文物信息的列表。每个元素是一个字典列表，每个字典代表该文物的一个字段及其值。
  - `filename`: 输出的 CSV 文件名（字符串），默认为 'objects_china.csv'。
- **返回**：无返回值。函数会在当前目录下生成 CSV 文件，保存所有文物的信息。


### 3. **注意事项**

- **网络结构依赖性强**：脚本依赖网站的 HTML 结构（尤其是 .detailField 和图片路径结构），若网站结构变动或字段名调整（如类名变更、字段位置变动），会导致字段提取失败，应定期检查网页源代码并更新选择器。
- **静态Cookie可能过期**：脚本中手动设置的 cookies 是静态值（从浏览器复制粘贴），这些Cookie可能在数小时或数天内过期，失效后会导致请求异常或访问被拒绝，若遇到问题，需手动更新Cookie。
- **频繁访问风险**：加time.sleep(1)控制访问频率，但长期或高频运行仍可能触发网站防爬策略

------

### 4. **输出字段说明**

在命令行执行脚本后，会将爬取到的文物数据保存为 CSV 文件。每条记录包括以下字段：

- `Title`：文物标题
- `Place`：产地
- `Time`：制作时间
- `Period`：历史时期
- `Medium`：材质
- `Dimensions`：尺寸
- `Credit Line`：来源
- `Object Number`：馆藏编号
- `Department`：馆藏部门
- `Classification`：分类
- `On View`：是否展出
- `Gallery`：展厅
- `Description`：附加说明
- `Image URL`：高清图像链接
- `Detail URL`：详情页链接

------

### 5. **依赖模块说明**
- `selenium`：用于控制浏览器获取动态加载页面。
- `BeautifulSoup`：用于解析网页 HTML，提取字段。
- `pandas`：用于保存结构化数据到 CSV 文件。
- `time`：用于延迟等待页面加载。
- `re`：正则表达式匹配字段（如图像 URL）。
- `tpdm`：进度条展示。
---

### 芝加哥艺术博物馆

`Spider/Art_Institute_Chicago`

该脚本（pachong.py）用于从芝加哥艺术博物馆（Art Institute of Chicago, AIC）的 API 爬取与中国相关的文物信息，并将结果保存为 CSV 文件。文物信息包括文物的标题、创建时间、描述、详情页链接及图片链接。

#### 功能简介：

1. **爬取文物信息**：从 AIC API 获取包含“China”关键词的文物列表。
2. **抓取文物描述**：访问每个文物的详情页并提取描述信息。
3. **保存为 CSV**：将抓取到的文物数据保存为 UTF-8 编码的 CSV 文件。

------

### 主要模块与函数说明

#### 1. **全局配置参数**

```python
HEADERS = {
    "User-Agent": "Mozilla/5.0"
}

DEFAULT_OUTPUT_PATH = "data/artic_chinese_artifacts.csv"
DEFAULT_MAX_PAGES = 10
```

- **HEADERS**：请求头，模拟浏览器访问，避免被网站封禁。
- **DEFAULT_OUTPUT_PATH**：默认保存文件路径，存储爬取的文物数据。
- **DEFAULT_MAX_PAGES**：默认最大爬取页数，每页最多获取100条数据。

#### 2. **功能函数**

##### 2.1 `get_artworks_from_api(page=1, limit=100)`

该函数通过发送 HTTP 请求从 AIC 的 API 获取与“China”相关的文物列表（不包含详细信息）。

- **参数**：
  - `page`: 页码，从1开始。
  - `limit`: 每页最多获取的文物数，最大为100条。
- **返回**：返回文物字典列表，每个字典包含文物的基础信息，如：`id`、`title`、`date_display`、`image_id`。

##### 2.2 `construct_detail_url(art_id)`

根据文物的 ID 构造其详情页 URL。

- **参数**：
  - `art_id`: 文物的 ID。
- **返回**：返回详情页的完整 URL。

##### 2.3 `construct_image_url(image_id)`

根据图像的 `image_id` 构造高清图像的 URL。

- **参数**：
  - `image_id`: 图像的 ID。
- **返回**：高清图像的 URL。

##### 2.4 `get_description_from_page(detail_url)`

访问文物的详情页，并从 HTML 中提取文物的描述信息（如果存在）。

- **参数**：
  - `detail_url`: 文物详情页的 URL。
- **返回**：返回文物描述文本。如果没有描述，则返回空字符串。

##### 2.5 `crawl_all_artworks(max_pages=5)`

主爬虫逻辑。该函数会抓取多个页面的数据，每个页面最多包含 `limit` 条文物数据。对于每个文物，还会抓取其详细描述信息。

- **参数**：
  - `max_pages`: 最大爬取页数。
- **返回**：返回包含所有文物信息的列表，每条信息是一个字典，包含文物的标题、时间、描述、详情页链接和图像 URL。

##### 2.6 `save_to_csv(data, filename)`

将抓取的文物数据保存为 CSV 文件。

- **参数**：
  - `data`: 包含所有文物数据的列表，每个元素是一个字典。
  - `filename`: 输出文件路径，保存为 CSV 文件。
- **返回**：无返回值，数据将保存到指定路径的 CSV 文件中。

------

### 3. **命令行参数说明**

#### 3.1 `--output`

- **功能**：指定输出 CSV 文件的路径。
- **默认值**：`data/artic_chinese_artifacts.csv`。
- **示例**：`--output "output/artifacts.csv"`

#### 3.2 `--pages`

- **功能**：指定要爬取的最大页数。
- **默认值**：`10`。
- **示例**：`--pages 5`（表示爬取 5 页数据）

------

### 4. **命令行执行**

该脚本支持通过命令行参数来配置爬虫的输出路径和最大爬取页数。例如，要爬取 3 页文物数据并保存为指定文件，可以执行以下命令：

```
python pachong.py --output "data/artifacts.csv" --pages 3
```

------

### 5. **注意事项**

- **访问限制**：该脚本通过模拟浏览器请求来爬取数据，但请注意不要频繁访问网站，以避免被封禁。使用 `time.sleep(0.5)` 来降低请求频率。
- **数据来源**：数据来自芝加哥艺术博物馆的公开 API，确保在遵守 API 使用条款的情况下使用该脚本。
- **错误处理**：如果访问详情页失败或网络出现问题，爬虫会记录错误并继续抓取其他文物。

------

### 6. **示例输出**

在命令行执行脚本后，会将爬取到的文物数据保存为 CSV 文件。每条记录包括以下字段：

- `title`：文物标题
- `time`：文物创建时间
- `description`：文物描述（如有）
- `detail_url`：文物详情页链接
- `image_url`：文物图像链接

例如，CSV 文件内容可能如下所示：

```cvs
title,time,description,detail_url,image_url
"Tree Peonies in Full Bloom",1911,"This boldly decorative painting is a significant document of Chinese-American relations...",https://www.artic.edu/artworks/25247,https://www.artic.edu/iiif/2/d2b56c9c-0824-9d66-fab6-2b02493f6855/full/843,/0/default.jpg
```

------

### 7. **依赖项**

- `requests`：用于发送 HTTP 请求。
- `pandas`：用于处理和保存数据为 CSV 文件。
- `BeautifulSoup`：用于解析和提取 HTML 内容。
- `argparse`：用于解析命令行参数。
- `os`：用于处理文件路径和目录。

